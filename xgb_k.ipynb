{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb version : 1.0.1\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print('本地 xgb version : 1.0.1','运行xgb_version:', xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import gc\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import stats,sparse\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import math\n",
    "from tqdm import *\n",
    "from scipy.stats import entropy, pearsonr\n",
    "\n",
    "# import catboost as cbt\n",
    "# print('catboost version :', cbt.__version__)\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score,accuracy_score,roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score,recall_score,accuracy_score,log_loss,precision_score\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import label_binarize, LabelBinarizer\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.stats import pearsonr,spearmanr,kendalltau,entropy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取数据~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train_tag = pd.read_csv('data/data32516/训练数据集_tag.csv')\n",
    "    train_trd = pd.read_csv('data/data32516/训练数据集_trd.csv')\n",
    "    train_beh = pd.read_csv('data/data32516/训练数据集_beh.csv')\n",
    "    del train_beh['page_tm']\n",
    "    train_beh.columns = ['id', 'flag', 'page_no', 'page_tm']\n",
    "    print('train table: tag id {}, trd id {}, beh id {}'.format(train_tag.id.nunique(), train_trd.id.nunique(), train_beh.id.nunique()))\n",
    "    print('all train id number: ', len(set(train_tag.id)|(set(train_trd.id)|set(train_beh.id))))\n",
    "    # print(len(set(train_tag.id)&(set(train_trd.id)|set(train_beh.id))))\n",
    "    \n",
    "    print(train_tag.shape, train_trd.shape, train_beh.shape)\n",
    "\n",
    "    test_tag = pd.read_csv('data/data32516/评分数据集_tag_b.csv')\n",
    "    test_trd = pd.read_csv('data/data32516/评分数据集_trd_b.csv')\n",
    "    test_beh = pd.read_csv('data/data32516/评分数据集_beh_b.csv')\n",
    "    del test_beh['page_tm']\n",
    "    test_beh.columns = ['id', 'page_no', 'page_tm']\n",
    "    print('test table: tag id {}, trd id {}, beh id {}'.format(test_tag.id.nunique(), test_trd.id.nunique(), test_beh.id.nunique()))\n",
    "    # print(len(set(test_tag.id)&(set(test_trd.id)|set(test_beh.id))))\n",
    "    print('all test id number: ', len(set(test_tag.id)|(set(test_trd.id)|set(test_beh.id))))\n",
    "    print(test_tag.shape, test_trd.shape, test_beh.shape)\n",
    "    \n",
    "    tag = train_tag.append(test_tag, sort=False).reset_index(drop=True)\n",
    "    trd = train_trd.append(test_trd, sort=False).reset_index(drop=True)\n",
    "    beh = train_beh.append(test_beh, sort=False).reset_index(drop=True)\n",
    "    return tag, trd, beh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train table: tag id 39923, trd id 31993, beh id 11913\n",
      "all train id number:  39923\n",
      "(39923, 43) (1367211, 8) (934282, 4)\n",
      "test table: tag id 4000, trd id 3190, beh id 1232\n",
      "all test id number:  4000\n",
      "(4000, 42) (142645, 7) (95669, 3)\n"
     ]
    }
   ],
   "source": [
    "tag, trd, beh = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['trd_id', 'beh_id']:\n",
    "    tag[i] = 0\n",
    "    if i == 'trd_id':\n",
    "        tag.loc[tag.id.isin(trd.id.unique()), i] = 1\n",
    "    else:\n",
    "        tag.loc[tag.id.isin(beh.id.unique()), i] = 1\n",
    "tag['sample'] = tag[['trd_id', 'beh_id','flag']].astype(str).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`tag`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_num_cols = [i for i in tag.dtypes[tag.dtypes != object].index if i not in ['id','flag','trd_id', 'beh_id','sample']]\n",
    "tag_cate_cols = [i for i in tag.columns if i not in tag_num_cols+['id','flag', 'trd_id', 'beh_id','sample']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_to_num_col = []\n",
    "for col in tag_cate_cols:\n",
    "    try:\n",
    "        tag[col] = tag[col].replace('\\\\N', np.nan)\n",
    "        tag[col] = tag[col].astype('float')\n",
    "        # print(col)\n",
    "        cate_to_num_col.append(col)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_cate_cols = [i for i in tag_cate_cols if i not in cate_to_num_col]\n",
    "tag['gdr_cd'] = tag['gdr_cd'].map({'M':1,'F':0})\n",
    "tag = pd.get_dummies(columns=tag_cate_cols,data=tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"理财\"\"\"\n",
    "l12_col = ['l12mon_buy_fin_mng_whl_tms', 'l12_mon_fnd_buy_whl_tms', 'l12_mon_gld_buy_whl_tms']\n",
    "tag['l12mon_buy_sum'] = tag[l12_col].sum(axis=1)\n",
    "for col in l12_col:\n",
    "    tag[f'{col}_ratio'] = tag[col] / (tag['l12mon_buy_sum']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_col = ['cur_debit_cnt', 'cur_credit_cnt', 'cur_debit_min_opn_dt_cnt',\n",
    "'cur_credit_min_opn_dt_cnt', 'cur_debit_crd_lvl','hld_crd_card_grd_cd']\n",
    "tag.loc[tag['cur_credit_min_opn_dt_cnt']==-1,'hld_crd_card_grd_cd'] = -1\n",
    "for col in [ 'cur_debit_min_opn_dt_cnt', 'cur_credit_min_opn_dt_cnt',]:\n",
    "    tag[col] = tag[col].replace(-1,0)\n",
    "tag['debit-credit'] = tag['cur_debit_min_opn_dt_cnt'] - tag['cur_credit_min_opn_dt_cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **trd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_fe(data, value, ind, column, func, kk):\n",
    "    pivot = pd.pivot_table(data, values=[value], index=ind, columns=column,aggfunc=func)\n",
    "    pivot.columns = [value + f'_{i}_{j}_{kk}' for i in pivot.columns.levels[0] for j in pivot.columns.levels[2]]\n",
    "    pivot = pivot.reset_index().fillna(0)\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35183, 15)\n",
      "(35183, 15)\n",
      "(35183, 22)\n",
      "(35183, 22)\n",
      "(35183, 22)\n",
      "(35183, 22)\n"
     ]
    }
   ],
   "source": [
    "for col in ['Dat_Flg1_Cd', 'Dat_Flg3_Cd', 'Trx_Cod1_Cd']:\n",
    "    temp = pivot_fe(trd, 'cny_trx_amt', 'id', col, ['max', 'min', 'std', 'mean', 'median', 'sum','count'], col)\n",
    "    print(temp.shape)\n",
    "    temp.columns = ['id'] + temp.columns.tolist()[1:]\n",
    "    print(temp.shape)\n",
    "    tag = tag.merge(temp, on = 'id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trd['Trx_Cod2_Cd_count'] = trd['Trx_Cod2_Cd'].map(trd['Trx_Cod2_Cd'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {}\n",
    "for i in ['Dat_Flg1_Cd', 'Dat_Flg3_Cd', 'Trx_Cod1_Cd', 'Trx_Cod2_Cd']:\n",
    "    # aggs[f'{i}_count'] = ['min']\n",
    "    if i == 'Dat_Flg1_Cd':\n",
    "        aggs[i] = ['nunique', 'count']\n",
    "    else:\n",
    "        aggs[i] = ['nunique']\n",
    "aggs['Trx_Cod2_Cd_count'] = ['max', 'min', 'std', 'mean']\n",
    "aggs['cny_trx_amt'] = ['sum', 'mean']\n",
    "agg_df=trd.groupby('id').agg(aggs)\n",
    "agg_df.columns = ['trd'+'_'+'_'.join(col).strip() for col in agg_df.columns.values]\n",
    "agg_df=agg_df.reset_index()\n",
    "tag = tag.merge(agg_df, on = 'id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['cny_trx_amt_count_B_Dat_Flg1_Cd', 'cny_trx_amt_count_C_Dat_Flg1_Cd',\n",
    " 'cny_trx_amt_count_A_Dat_Flg3_Cd', 'cny_trx_amt_count_B_Dat_Flg3_Cd',\n",
    " 'cny_trx_amt_count_C_Dat_Flg3_Cd', 'cny_trx_amt_count_1_Trx_Cod1_Cd',\n",
    " 'cny_trx_amt_count_2_Trx_Cod1_Cd', 'cny_trx_amt_count_3_Trx_Cod1_Cd']:\n",
    "    tag[f'{i}_ratio'] = tag[i] / tag['trd_Dat_Flg1_Cd_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tfidf\"\"\"\n",
    "feat = trd[['id','Trx_Cod2_Cd']]\n",
    "feat['Trx_Cod2_Cd'] = feat['Trx_Cod2_Cd'].astype(str)\n",
    "feat = feat.groupby(['id'])['Trx_Cod2_Cd'].agg(lambda x: ' '.join(x)).reset_index(name='Trx_Cod2_Cd_list')\n",
    "tf_idf = TfidfVectorizer(max_features=30)\n",
    "tf_vec = tf_idf.fit_transform(feat['Trx_Cod2_Cd_list'].values.tolist())\n",
    "# svd = TruncatedSVD(n_components=16, n_iter=10, random_state=2019)\n",
    "# svd_vec = svd.fit_transform(tf_vec)\n",
    "tf_df = pd.DataFrame(tf_vec.toarray())\n",
    "tf_df['id'] = feat['id'].values\n",
    "tf_df.columns = ['Trx_Cod2_Cd_svd_vec_'+str(i+1) for i in range(30)]+ ['id']\n",
    "tag = tag.merge(tf_df,on='id', how='left')\n",
    "del tf_df,feat;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"时间统计\"\"\"\n",
    "trd['trx_tm'] = pd.to_datetime(trd['trx_tm'])\n",
    "trd['trx_tm_mon'] = trd['trx_tm'].dt.month\n",
    "trd['trx_tm_day'] = trd['trx_tm'].dt.day\n",
    "trd['trx_tm_dayofyear'] = trd['trx_tm'].dt.dayofyear\n",
    "trd['trx_tm_dayofyear'] = trd['trx_tm_dayofyear'] - trd['trx_tm_dayofyear'].min()\n",
    "trd['trx_tm_hour'] = trd['trx_tm'].dt.hour\n",
    "trd['trx_tm_weekday'] = trd['trx_tm'].dt.weekday\n",
    "trd['trx_tm_wy'] = trd['trx_tm'].dt.weekofyear\n",
    "trd['trx_tm_wy'] = trd['trx_tm_wy'] - trd['trx_tm_wy'].min()\n",
    "trd['trx_tm_是否周末'] = trd['trx_tm_weekday'].apply(lambda x:1 if x >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {\n",
    "    'trx_tm_dayofyear':['nunique', 'max', 'min', np.ptp],\n",
    "}\n",
    "agg_df=trd.groupby('id').agg(aggs)\n",
    "agg_df.columns = ['trd'+'_'+'_'.join(col).strip() for col in agg_df.columns.values]\n",
    "agg_df=agg_df.reset_index()  \n",
    "tag = tag.merge(agg_df, on = 'id', how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按月统计 sum\n",
    "temp = pivot_fe(trd, 'cny_trx_amt', 'id', 'trx_tm_mon', ['sum'], 'month')\n",
    "temp['5-6'] = temp['cny_trx_amt_sum_5_month'] - temp['cny_trx_amt_sum_6_month']\n",
    "tag = tag.merge(temp,on='id', how='left')\n",
    "#按工作日统计 mean\n",
    "temp = pivot_fe(trd, 'cny_trx_amt', 'id', 'trx_tm_是否周末', ['mean'], '是否周末')\n",
    "tag = tag.merge(temp,on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按周统计 'sum','mean'\n",
    "temp = pivot_fe(trd, 'cny_trx_amt', 'id', 'trx_tm_wy', ['sum','mean'], 'wy')\n",
    "tag = tag.merge(temp,on='id', how='left')\n",
    "\n",
    "temp = trd.groupby(['id', 'trx_tm_wy'])['cny_trx_amt'].sum().reset_index(name = 'sum')\n",
    "tag['trx_tm_wy_spearmanr_wy'] = tag['id'].map(temp.groupby('id').apply(lambda x:spearmanr(x['trx_tm_wy'], x['sum'])[0]))\n",
    "\n",
    "temp = trd.groupby(['id', 'trx_tm_wy'])['cny_trx_amt'].count().reset_index(name = 'count')\n",
    "tag['trx_tm_wy_spearmanr_count'] = tag['id'].map(temp.groupby('id').apply(lambda x:spearmanr(x['trx_tm_wy'], x['count'])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pivot_fe(trd, 'cny_trx_amt', 'id', 'trx_tm_wy', ['count'], 'wy')\n",
    "temp.drop(columns=['cny_trx_amt_count_2_wy',\n",
    "       'cny_trx_amt_count_3_wy', 'cny_trx_amt_count_4_wy',\n",
    "       'cny_trx_amt_count_5_wy', 'cny_trx_amt_count_6_wy',\n",
    "       'cny_trx_amt_count_7_wy'], inplace=True)\n",
    "tag = tag.merge(temp,on='id', how='left')\n",
    "for i in temp.columns[1:]:\n",
    "    tag[i] = tag[i] / tag['trd_Dat_Flg1_Cd_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32147, 13)\n",
      "(32147, 13)\n",
      "(32147, 9)\n",
      "(32147, 9)\n",
      "(33130, 13)\n",
      "(33130, 13)\n",
      "(33130, 9)\n",
      "(33130, 9)\n"
     ]
    }
   ],
   "source": [
    "trd_b = trd[trd['Dat_Flg1_Cd'] == 'B'].copy()\n",
    "for col in ['Dat_Flg3_Cd', 'Trx_Cod1_Cd']:\n",
    "    temp = pivot_fe(trd_b, 'cny_trx_amt', 'id', col, ['max', 'min', 'std', 'mean'], 'b')\n",
    "    print(temp.shape)\n",
    "    temp.columns = ['id'] + temp.columns.tolist()[1:]\n",
    "    print(temp.shape)\n",
    "    tag = tag.merge(temp, on = 'id', how='left')\n",
    "trd_b = trd[trd['Dat_Flg1_Cd'] == 'C'].copy()\n",
    "for col in ['Dat_Flg3_Cd', 'Trx_Cod1_Cd']:\n",
    "    temp = pivot_fe(trd_b, 'cny_trx_amt', 'id', col, ['max', 'min', 'std', 'mean'], 'c')\n",
    "    print(temp.shape)\n",
    "    temp.columns = ['id'] + temp.columns.tolist()[1:]\n",
    "    print(temp.shape)\n",
    "    tag = tag.merge(temp, on = 'id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag['cur_debit_cnt_div'] = tag['cur_debit_min_opn_dt_cnt'] / tag['cur_debit_cnt']\n",
    "tag['cur_credit_cnt_div'] = tag['cur_credit_min_opn_dt_cnt'] / tag['cur_credit_cnt']\n",
    "for sta in ['max', 'min', 'std', 'mean','median']:\n",
    "    tag['cur_debit_crd_lvl_'+sta] = tag.groupby('cur_debit_crd_lvl')['cur_debit_min_opn_dt_cnt'].transform(sta)\n",
    "    tag['hld_crd_card_grd_cd_'+sta] = tag.groupby('hld_crd_card_grd_cd')['cur_credit_min_opn_dt_cnt'].transform(sta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sta in ['max', 'min', 'std', 'mean','median']:\n",
    "    tag['l1y_crd_card_csm_amt_dlm_cd_sum_'+sta] = tag.groupby('cur_debit_crd_lvl')['cny_trx_amt_sum_B_Dat_Flg1_Cd'].transform(sta)\n",
    "    # tag['l1y_crd_card_csm_amt_dlm_cd_sum1_'+sta] = tag.groupby('l1y_crd_card_csm_amt_dlm_cd')['cny_trx_amt_sum_B_Dat_Flg1_Cd'].transform(sta)\n",
    "    # tag['tot_ast_lvl_cd_mean_'+sta] = tag.groupby('hld_crd_card_grd_cd')['cny_trx_amt_sum_C_Dat_Flg1_Cd'].transform(sta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tag.groupby(['pl_crd_lmt_cd'])['his_lng_ovd_day'].agg(['max','min', 'std', 'mean']).reset_index()\n",
    "temp.columns = ['pl_crd_lmt_cd'] + ['his_lng_ovd_day_'+i for i in ['max','min', 'std', 'mean']]\n",
    "tag = tag.merge(temp,on='pl_crd_lmt_cd', how='left')\n",
    "temp = tag.groupby(['pl_crd_lmt_cd'])['ovd_30d_loan_tot_cnt'].agg(['max', 'std', 'mean']).reset_index()\n",
    "temp.columns = ['pl_crd_lmt_cd'] + ['ovd_30d_loan_tot_cnt_'+i for i in ['max','std', 'mean']]\n",
    "tag = tag.merge(temp,on='pl_crd_lmt_cd', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#510\n",
    "for sta in ['sum']:\n",
    "    tag['pot_ast_lvl_cd_sumb_'+sta] = tag.groupby('pot_ast_lvl_cd')['cny_trx_amt_sum_B_Dat_Flg1_Cd'].transform(sta)\n",
    "    tag['tot_ast_lvl_cd_sumb_'+sta] = tag.groupby('tot_ast_lvl_cd')['cny_trx_amt_sum_B_Dat_Flg1_Cd'].transform(sta)\n",
    "    tag['pot_ast_lvl_cd_sumc_'+sta] = tag.groupby('pot_ast_lvl_cd')['cny_trx_amt_sum_C_Dat_Flg1_Cd'].transform(sta)\n",
    "    tag['tot_ast_lvl_cd_sumc_'+sta] = tag.groupby('tot_ast_lvl_cd')['cny_trx_amt_sum_C_Dat_Flg1_Cd'].transform(sta)\n",
    "\n",
    "    tag['hld_crd_card_grd_cd_sumb_'+sta] = tag.groupby('hld_crd_card_grd_cd')['cny_trx_amt_sum_B_Dat_Flg1_Cd'].transform(sta)\n",
    "    tag['cur_debit_crd_lvl_sumb_'+sta] = tag.groupby('cur_debit_crd_lvl')['cny_trx_amt_sum_B_Dat_Flg1_Cd'].transform(sta)\n",
    "\n",
    "tag['fagongzi'] = tag['cur_debit_min_opn_dt_cnt'] - tag['frs_agn_dt_cnt'].replace(-1,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag['beh_id'] = 1\n",
    "train = tag[~tag['flag'].isnull()].reset_index(drop=True)\n",
    "test = tag[tag['flag'].isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39923, 266) (4000, 266)\n"
     ]
    }
   ],
   "source": [
    "del_col=['cny_trx_amt_min_A_b', 'cny_trx_amt_min_B_b',\n",
    " 'cny_trx_amt_max_1_b', 'cny_trx_amt_min_1_b', 'cny_trx_amt_min_3_b',\n",
    " 'cny_trx_amt_std_1_b', 'cny_trx_amt_mean_1_b', 'cny_trx_amt_max_A_c',\n",
    " 'cny_trx_amt_max_B_c', 'cny_trx_amt_max_C_c', 'cny_trx_amt_min_C_c',\n",
    " 'cny_trx_amt_mean_C_c', 'cny_trx_amt_max_2_c', 'cny_trx_amt_min_2_c',\n",
    " 'cny_trx_amt_std_2_c', 'cny_trx_amt_mean_2_c', 'cur_debit_crd_lvl_median',\n",
    " ]\n",
    "col=[i for i in train.columns if i not in ['id', 'flag','sample']+del_col]\n",
    "X_train=train[col].copy()\n",
    "y_train=train['flag'].copy().astype(int)\n",
    "X_test=test[col].copy()\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T06:16:01.504250Z",
     "start_time": "2020-05-12T06:16:01.498267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mean_auc =  0.7599745786952503 0.004\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "seed = 2021\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "xgb_pred_te_all = 0\n",
    "xgb_auc_mean = 0\n",
    "xgb_auc_mean2 = 0\n",
    "f1 = []\n",
    "logsocre = []\n",
    "oof_xgb = np.zeros((len(X_train), ))\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    y_tr, y_val = y_train.iloc[train_index].copy(), y_train.iloc[test_index].copy()\n",
    "    X_tr, X_val= X_train.iloc[train_index,:].copy(), X_train.iloc[test_index,:].copy()\n",
    "    print( \"\\nFold \", i+1)\n",
    "\n",
    "    xgb_tr = xgb.DMatrix(X_tr, y_tr)\n",
    "    xgb_val = xgb.DMatrix(X_val, y_val)\n",
    "    xgb_te = xgb.DMatrix(X_test)\n",
    "    xgb_params = {\"objective\": 'binary:logistic',\n",
    "                  \"booster\" : \"gbtree\",\n",
    "                  \"eta\": 0.1,\n",
    "                  \"max_depth\":4,#9\n",
    "                  \"subsample\": 0.8,\n",
    "                  'eval_metric':'auc',\n",
    "                #   \"colsample_bytree\": 0.6,\n",
    "                  \"colsample_bylevel\":0.8,\n",
    "                  'gpu_id':0,\n",
    "                  'tree_method':'gpu_hist',\n",
    "                #   'scale_pos_weigh':np.sum(y_tr==0)/np.sum(y_tr==1),\n",
    "                #   'gamma':0.2,\n",
    "                  'lambda':5,                                 \n",
    "                #   \"thread\":8,\n",
    "                  \"seed\": 666\n",
    "                  }\n",
    "    watchlist = [(xgb_tr, 'train'), (xgb_val, 'eval')]\n",
    "    xgb_model =xgb.train(xgb_params,\n",
    "                 xgb_tr,\n",
    "                 num_boost_round = 2000,\n",
    "                 evals =watchlist,\n",
    "                 verbose_eval=100,\n",
    "                 early_stopping_rounds=100\n",
    "                 ) \n",
    "    pred = xgb_model.predict(xgb_val, ntree_limit=xgb_model.best_ntree_limit)\n",
    "    oof_xgb[test_index] = pred\n",
    "    auc = roc_auc_score(y_val, pred)\n",
    "    print( \" auc_score = \", auc )\n",
    "    f1.append(auc)\n",
    "    print(\"*\"*100)\n",
    "    pred_te = xgb_model.predict(xgb_te,ntree_limit=xgb_model.best_ntree_limit)\n",
    "    xgb_pred_te_all = xgb_pred_te_all + pred_te / K\n",
    "print(\"=\"*50+'result'+\"=\"*50)\n",
    "print( \" mean_auc = \", np.mean(f1) ,np.std(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T06:15:15.144174Z",
     "start_time": "2020-05-12T06:15:15.136195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本地线下分数：mean_auc=0.7599 std_auc=0.0043573498880776825\n"
     ]
    }
   ],
   "source": [
    "print('本地线下分数：mean_auc=0.7599 std_auc=0.004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test[['id']].copy()\n",
    "sub['违约预测概率'] = xgb_pred_te_all\n",
    "sub.to_csv(\"xgb_7599.txt\", sep=\"\\t\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
